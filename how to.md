ููุชุงุฒ! ุฅุฐุง ููุช ุชุนูู ุนูู ูุดุฑูุน ูุญูู ูู n8n ููุญุชูู ุนูู:

Chat trigger

AI agent

LLaMA model (ูููุฐุฌ ูุบูู ูุญูู ูุซู LLaMA 2 ุฃู 3)

ูุชุฑุบุจ ูู ุชุบุฐูุฉ ูููุฐุฌ LLaMA ุจุจูุงูุงุช ุฎุงุตุฉ (ูุซูุงู: ูููุงุชุ ูุตูุตุ ุฏุฑูุณุ ูุงุนุฏุฉ ูุนุฑููุฉ...)ุ ูุฅููู ุงูุฎุทูุงุช ุงูุนูููุฉ ูุชุญุฏูุฏ ุฃูู ุชูุถุน ูุฐู ุงูุจูุงูุงุช ู ููู ูุชู ุงุณุชุนูุงููุง ุฏุงุฎู n8n ูllama:

โ ุฃููุงู: ุฃูู ุชุถุน ุงูุจูุงูุงุช ูุชุบุฐูุฉ LLaMA
ูุนุชูุฏ ููุงู ูุถุน ุงูุจูุงูุงุช ุนูู ุงูุทุฑููุฉ ุงูุชู ุชุณุชุฎุฏู ุจูุง LLaMA:

1. ุฅุฐุง ููุช ุชุณุชุนูู LLaMA ุนุจุฑ ollama:
ูุซู ollama run llama2 ุฃู ollama run codellama

ููููู ุงุณุชุฎุฏุงู ููุฒุฉ ุชุณูู embedding + RAG (ุงุณุชุฑุฌุงุน ุงููุนุฑูุฉ).

ูู ูุฐู ุงูุญุงูุฉุ ุงูุจูุงูุงุช ุชูุถุน ูู ูุงุนุฏุฉ ุจูุงูุงุช ุฃู ูููุงุช ูุตูุฉ ุซู ุชูุญููู ุฅูู vectors ููุชู ุงุณุชุฏุนุงุคูุง ูู ุงููprompt.

2. ุฅุฐุง ููุช ุชุณุชุนูู LLaMA ุฏุงุฎู Langchain ุฃู LLM local server:
ุจุฅููุงูู ุชุญููู ุงูุฏุงุชุง ุนูู ุดูู ูููุงุช .txt, .md, .pdf, ุฃู .json.

ุจุนุฏูุง ุชุณุชุฎุฏู Document Loaders + Text Splitter + Embedding Model + Vector Store.

โ ุซุงููุงู: ููู ุชุณุชุนูููุง ูู n8n ูุน AI Agent
โ๏ธ ุงูููุฑุฉ ุงูุนุงูุฉ:
ุงููุตูุต ุฃู ุงูุจูุงูุงุช โ ุชูุญููู ุฅูู embeddings.

ุชูุฎุฒู ูู Vector DB (ูุซู Chroma, Weaviate, FAISS, ุฃู Pinecone).

ุงููAI Agent ูู n8n ูููู ุจู:

ุงุณุชูุจุงู ุงูุณุคุงู ูู ุงููุณุชุฎุฏู.

ุงุณุชุฎุฏุงู vector search ููุจุญุซ ุนู ุงูุฌูุงุจ ุงูุฃูุฑุจ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช.

ุชูุฑูุฑ ุงูุฌูุงุจ ูู context ุฅูู LLaMA.

ุชูููุฏ ุฅุฌุงุจุฉ ุฐููุฉ.

๐ฆ ูุซุงู ุนููู: ุงุณุชุนูุงู ollama + Chroma + n8n
1. ุชุซุจูุช ุงูุฃุฏูุงุช:
bash
Copier
Modifier
pip install langchain chromadb
2. ุฅุนุฏุงุฏ ุณูุฑุจุช Python ูุชุญููู ุงูุฏุงุชุง ุฅูู ูุงุนุฏุฉ vector:
python
Copier
Modifier
from langchain.vectorstores import Chroma
from langchain.embeddings import OllamaEmbeddings
from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# ุชุญููู ุงูุจูุงูุงุช
loader = TextLoader("your_data.txt")
docs = loader.load()

# ุชูุณูู ุงููุตูุต
splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(docs)

# ุชุญููู ุฅูู vectors
embedding = OllamaEmbeddings(model="llama2")
vectorstore = Chroma.from_documents(chunks, embedding, persist_directory="./db")
vectorstore.persist()
3. ุฏุงุฎู n8n:
ุฃูุดุฆ chat trigger.

ูุฑุฑ ุงููุต ุงูููุฏุฎู ุฅูู Webhook ุฃู Python node.

ููุฐ ุณูุฑุจุช ุงุณุชุฑุฌุงุน ุณูุงู:

python
Copier
Modifier
from langchain.vectorstores import Chroma
from langchain.embeddings import OllamaEmbeddings

query = $json["userInput"]

db = Chroma(persist_directory="./db", embedding_function=OllamaEmbeddings(model="llama2"))
results = db.similarity_search(query)

# ุงุณุชุฑุฌุงุน ุณูุงู ููุงุณุจ ูููprompt
return {
  "context": results[0].page_content
}
ุจุนุฏูุง ุฃุฑุณู ุงูุณูุงู ูุงูุณุคุงู ุฅูู LLaMA ุนุจุฑ HTTP Request ุฃู custom node.

๐ ุฅุฐุงูุ ุงูุจูุงูุงุช ุชูุถุน ูู:
ููุน ุงูุจูุงูุงุช	ุฃูู ุชูุถุนุ	ุทุฑููุฉ ุงูุงุณุชุฎุฏุงู
ูุตูุต .txt ุฃู .md	ูุฌูุฏ ูุญูู (ูุซูุงู: ./data/)	ุชุญููููุง ุจุงูู Python ูุชุญููููุง ุฅูู vectors
PDF ุฃู JSON	ููุณ ุงูุดูุก	ุนุจุฑ Document Loader
ูุงุนุฏุฉ ุฌุงูุฒุฉ	ูุซู Pinecone ุฃู Weaviate	ุชุฎุฒู ูููุง ุงููembeddings ูุชุณุชุฎุฏู REST API

ูู ุชุฑุบุจ ุฃู ุฃุฌูุฒ ูู ุณูุฑุจุช n8n + Python ุฌุงูุฒ ุฎุทูุฉ ุจุฎุทูุฉุ
ุฅุฐุง ูุนูุ ููุท ุฃุนุทูู:

ูุซุงู ูู ุงูุจูุงูุงุช ุงูุชู ุชุฑูุฏ ุชุบุฐูุชูุง.

ููุน LLaMA ุงููุณุชุนูู (ูู ุชุณุชุนูู ollamaุ).

ูู ุนูุฏู n8n node ูุฎุตุต ูุชุดุบูู Python ุฃู Webhookุ

ุณุฃุฌูุฒ ูู ููููุง ูุงููุงู ุจุงูุชูุงูู.








Demander ร ChatGPT
Vous avez ditย:
ูุนู


ChatGPT a ditย:
รlรฉments mรฉmorisรฉs mis ร jour
ุฑุงุฆุน ูุง ูููููุงุฑุฏู ๐

ุจูุง ุฃูู ุชุนูู ูุญูููุง ุนูู n8n ูุชุณุชุนูู ูููุฐุฌ LLaMA ุนุจุฑ Ollama ูุชุฑูุฏ ุชุบุฐูุชู ุจุจูุงูุงุชู ุงูุฎุงุตุฉุ ุณุฃุฌูุฒ ูู ุงูุขู ุชูุงููุงู ูุงููุงู ุฌุงูุฒูุง:

โ ุจููุฉ ุงููุดุฑูุน:
kotlin
Copier
Modifier
n8n_workflow/
โ
โโโ n8n (ุชุนูู ูุญููุงู)
โโโ ollama (ูุนูู ูุญููุงู ูุน ูููุฐุฌ llama2)
โโโ data/
โ   โโโ my_knowledge.txt   โ ูููุงุช ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู
โโโ embedding.py          โ ุณูุฑุจุช ุชุญููู ุงููุตูุต ุฅูู ูุงุนุฏุฉ ูุนุฑููุฉ
โโโ query_context.py      โ ุณูุฑุจุช ุงุณุชุฑุฌุงุน ุงูุณูุงู ุงูููุงุณุจ ูุณุคุงู ุงููุณุชุฎุฏู
โโโ db/                   โ ูุงุนุฏุฉ ุงูุจูุงูุงุช (Chroma)
โ ุฅุนุฏุงุฏ Ollama ูุชุดุบูู LLaMA ูุญููุงู
bash
Copier
Modifier
ollama run llama2
โก ููู ุงูุจูุงูุงุช: data/my_knowledge.txt
ุถุน ููู ุงููุตูุต ุฃู ุงูุฏุฑูุณ ุฃู ุงููุนูููุงุช ุงูุชู ุชุฑูุฏ ุฃู ูุชุนูู ูููุง LLaMAุ ูุซูุงู:

python-repl
Copier
Modifier
ุงูููุงุกุฉ ุงูููููุฉ ูู ูุฌููุน ุงููุนุงุฑู ูุงูููุงุฑุงุช ุงูุชู ูุฌุจ ุฃู ูุชุญูู ุจูุง ุงููุฏุฑุณ ูู ุงููุณู.
ุฏูุฏุงูุชูู ุงูุฑูุงุถูุงุช ูุฑูุฒ ุนูู ูุจุงุฏุฆ ุงูุชุนููู ุจุงูุฃูุซูุฉ ูุงูุชุฌุฑูุจ.
...
โข ุณูุฑุจุช 1: embedding.py โ ุชุญููู ุงููุตูุต ุฅูู ูุงุนุฏุฉ ูุนุฑููุฉ
python
Copier
Modifier
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import OllamaEmbeddings

# ุชุญููู ุงูููู
loader = TextLoader("data/my_knowledge.txt")
documents = loader.load()

# ุชูุณูู ุงููุตูุต ุฅูู ูุทุน ุตุบูุฑุฉ
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(documents)

# ุฅูุดุงุก ูุงุนุฏุฉ Embeddings
embedding = OllamaEmbeddings(model="llama2")
vectorstore = Chroma.from_documents(documents=chunks, embedding=embedding, persist_directory="./db")
vectorstore.persist()
print("โ ูุงุนุฏุฉ ุงููุนุฑูุฉ ุฌุงูุฒุฉ.")
๐ ุดุบู ูุฐุง ุงูุณูุฑุจุช ูุฑุฉ ูุงุญุฏุฉ ููุท ุนูุฏ ุชุญุฏูุซ ุงููุตูุต.

โฃ ุณูุฑุจุช 2: query_context.py โ ุงูุจุญุซ ูู ุงููุงุนุฏุฉ ูุงุณุชุฑุฌุงุน ุงูุณูุงู
python
Copier
Modifier
import sys
from langchain.vectorstores import Chroma
from langchain.embeddings import OllamaEmbeddings

# ุงูุณุคุงู ูุฃุชู ูู n8n
user_query = sys.argv[1]

# ุงุณุชุฑุฌุงุน ูู ุงููุงุนุฏุฉ
db = Chroma(persist_directory="./db", embedding_function=OllamaEmbeddings(model="llama2"))
results = db.similarity_search(user_query, k=2)

# ุทุจุงุนุฉ ุงูุณูุงู ุงููุณุชุฎุฑุฌ (n8n ููุชูุท ุงูุฅุฎุฑุงุฌ)
for r in results:
    print(r.page_content)
โค ุฏุงุฎู n8n: ุฅูุดุงุก ุงูู Workflow
๐ฌ 1. Chat Trigger:
ูุณุชุฎุฏู Webhook ุฃู ุฃู Chat Interface.

๐ง 2. Node: Execute Command
ุดุบูู ุณูุฑุจุช query_context.py ุจูุฐุง ุงูุดูู:

bash
Copier
Modifier
python3 query_context.py "{{ $json['userMessage'] }}"
๐งพ 3. Node: HTTP Request
ููุฑุณู ุงูุณุคุงู + ุงูุณูุงู ุฅูู LLaMA (Ollama API ูุญูู):

http
Copier
Modifier
POST http://localhost:11434/api/generate
Content-Type: application/json

{
  "model": "llama2",
  "prompt": "ุงุณุชุนูู ุงููุนูููุงุช ุงูุชุงููุฉ ููุฅุฌุงุจุฉ:\n{{ $json['context'] }}\n\nุงูุณุคุงู: {{ $json['userMessage'] }}",
  "stream": false
}
โ ุงููุชูุฌุฉ:
ุงููุณุชุฎุฏู ูุฑุณู ุณุคุงูุงู ุนุจุฑ chat.

ูุชู ุงูุจุญุซ ูู ูุงุนุฏุฉ ูุนุฑููุฉ ุฎุงุตุฉ.

ูุชู ุชุบุฐูุฉ LLaMA ุจุณูุงู ุฏููู.

LLaMA ูุฌูุจ ุจุฅุฌุงุจุงุช ุฐููุฉ ูุจููุฉ ุนูู ุจูุงูุงุชู.

ูู ุชุฑุบุจ ุฃู ุฃุฑุณู ูู ุงููููุงุช ุจุตูุบุฉ ุฌุงูุฒุฉ .zip ุฃู ุฃุฌูุฒูุง ุจุตูุบุฉ ูุดุฑูุน GitHubุ
ูุฅุฐุง ูุงูุช ูุฏูู ุฃูุซูุฉ ุญููููุฉ ูู ุงูุจูุงูุงุช (ูุซูุงู ููู ููู 10 ุฏุฑูุณ)ุ ุฃุฑุณููุง ูู ูุฃุฌูุฒ ูู ูุงุนุฏุฉ ูุนุฑููุฉ ูุงูุนูุฉ.







Vous avez ditย:
ุตูุฑุฉ ุชูุถุญ ุงููุดุฑูุน


ChatGPT a ditย:
N8n Llama Workflow

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
# ุจููุฉ ูุดุฑูุน n8n + LLaMA

๐ n8n_llama_project/
โ
โโโ ๐ data/
โ   โโโ my_knowledge.txt     # ููู ูุญุชูู ุนูู ุงููุนุงุฑู ุฃู ุงูุฏุฑูุณ ุงูุฎุงุตุฉ ุจู
โ
โโโ ๐ db/                   # ูุงุนุฏุฉ ุจูุงูุงุช Chroma ูุญูุธ ุงูู embeddings
โ
โโโ ๐ embedding.py          # ุณูุฑุจุช ูุญูู ุงููุตูุต ุฅูู vectors ููุฎุฒููุง ูู db/
โ
โโโ ๐ query_context.py      # ุณูุฑุจุช ูุฃุฎุฐ ุณุคุงู ููุณุชุฑุฌุน ุงูุณูุงู ุงูููุงุณุจ ูู ุงููุงุนุฏุฉ
โ
โโโ ๐ n8n (ูุงุฌูุฉ ุฑุณูููุฉ)
โ    โโโ Chat Trigger        --> userMessage
โ         โ
โ       Execute Command Node --> python3 query_context.py "{{ $json['userMessage'] }}"
โ         โ
โ       HTTP Request to Ollama API --> prompt ูุชุถูู ุงูุณูุงู + ุงูุณุคุงู
โ         โ
โ       ุงูุฑุฏ ุงูููุงุฆู ูู LLaMA โ ูุนูุฏ ุฅูู ุงููุณุชุฎุฏู
โ
โโโ ๐ง Ollama (LLaMA ูุญูู ูุนูู ุนูู http://localhost:11434)

# -----------------------------
# ุณููู ุงููุดุฑูุน:
# -----------------------------
# 1. ุงููุณุชุฎุฏู ูุณุฃู ุณุคุงูุงู.
# 2. n8n ูุฑุณู ุงูุณุคุงู ุฅูู ุณูุฑุจุช Python ูุณุชุฑุฌุน ุฃูุถู ุณูุงู.
# 3. ุงูุณูุงู + ุงูุณุคุงู ููุฑุณู ุฅูู LLaMA.
# 4. LLaMA ูููุชุฌ ุฌูุงุจุงู ูุจููุงู ุนูู ุงูุจูุงูุงุช ุงูุชู ููุฑุชูุง.
# 5. ุงูุฌูุงุจ ููุฑุณู ูููุณุชุฎุฏู.

# ๐ ููููู ุฅุถุงูุฉ ุฃููุงุน ูุชุนุฏุฏุฉ ูู ุงูุจูุงูุงุช (ูุตูุตุ ุฏุฑูุณุ ููุงูููุ ุฅูุฎ)
# ๐ ูููู ุชุญููู ุงููููุงุช PDF ูุงุญูุงู ุฅูู ูุตูุต ูุฅุถุงูุชูุง ุฅูู ุงููุงุนุฏุฉ.
# ๐ ุงููููุฐุฌ ูุตุจุญ ุฃูุซุฑ ุฏูุฉ ูููุง ุฒุงุฏุช ุงูุจูุงูุงุช ูุฌูุฏุชูุง.

ุชู ุฅูุดุงุก ุตูุฑุฉ ูุตูุฉ ุชูุถูุญูุฉ ููุดุฑูุนู ุชุญุช ุงุณู N8n Llama Workflow.
ุชูุธูุฑ ูุฐู ุงููุซููุฉ ูู ููููุงุช ุงููุดุฑูุน ูุงูุนูุงูุงุช ุจูููุง:

ูุฌูุฏุงุช ุงููุดุฑูุน ูุงููููุงุช ุงููููุฉ (data, db, ุณูุฑุจุชุงุช Python).

ุชุณูุณู ุงูุนูู ุฏุงุฎู n8n ูู Chat Trigger ุฅูู ุชูููุฐ LLaMA.

ุทุฑููุฉ ุชูุงุนู Ollama ูุน ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู.

ูู ุชุฑุบุจ ุงูุขู ุจุตูุฑุฉ ุฑุณูููุฉ (visual diagram) ุชูุซู ูุฐุง ุงูููููุ





Vous avez ditย:
ููุฆ ููู ููููุน githup


ChatGPT a ditย:

Analysรฉ
python
Toujours afficher les dรฉtails

Copier
from pathlib import Path

# ุฅุนุฏุงุฏ ูููู ูุฌูุฏ ูุดุฑูุน GitHub
project_name = "n8n-llama-custom-rag"
base_path = Path("/mnt/data") / project_name

folders = [
    "data",
    "db",
    ".github/workflows"
]

files = {
    "README.md": """# ๐ง n8n + LLaMA + Ollama + RAG

ูุดุฑูุน ูุญูู ูุชูุตูู n8n ูุน ูููุฐุฌ LLaMA ุนุจุฑ Ollama ุจุงุณุชุฎุฏุงู ุจูุงูุงุช ุฎุงุตุฉ (RAG - ุงุณุชุฑุฌุงุน ูุนุฒุฒ ุจุงููุตูุต).

## ๐ ุจููุฉ ุงููุดุฑูุน

n8n-llama-custom-rag/
โโโ data/ โ ูููุงุช ุงููุตูุต ุฃู ุงูุฏุฑูุณ ุงูุฎุงุตุฉ ุจู
โ โโโ my_knowledge.txt
โโโ db/ โ ูุงุนุฏุฉ ุจูุงูุงุช Chroma ูุชุฎุฒูู ุงูู embeddings
โโโ embedding.py โ ุณูุฑุจุช ูุชุญููู ุงูุจูุงูุงุช ุฅูู vectors
โโโ query_context.py โ ุณูุฑุจุช ูุงุณุชุฑุฌุงุน ุงูุณูุงู ุงููุฑุชุจุท ุจุงูุณุคุงู
โโโ .github/workflows/ โ ูููุงุช CI (ุฅู ููุฌุฏุช)
โโโ README.md โ ูุฐุง ุงูููู

shell
Toujours afficher les dรฉtails

Copier

## ๐ ุทุฑููุฉ ุงูุงุณุชุฎุฏุงู

### 1. ุฅุนุฏุงุฏ ุงูุจูุฆุฉ
```bash
pip install langchain chromadb
ollama run llama2
2. ุชุฌููุฒ ุงููุงุนุฏุฉ ุงููุนุฑููุฉ
bash
Toujours afficher les dรฉtails

Copier
python3 embedding.py
3. ุฏุงุฎู n8n
ุงุณุชูุจู ุณุคุงู ุงููุณุชุฎุฏู ุนุจุฑ Chat Trigger

ุดุบูู query_context.py ูุฌูุจ ุงูุณูุงู ุงูููุงุณุจ

ุฃุฑุณู ุงูุณูุงู + ุงูุณุคุงู ุฅูู ูููุฐุฌ LLaMA ุนุจุฑ API http://localhost:11434/api/generate

๐ฌ ูุซุงู ุนูู ุงุณุชุฏุนุงุก API ูู LLaMA
json
Toujours afficher les dรฉtails

Copier
POST /api/generate
{
  "model": "llama2",
  "prompt": "ุงููุนุฑูุฉ:\n...context...\nุงูุณุคุงู: ูุง ูู ุงูููุงุกุฉ ุงูููููุฉุ",
  "stream": false
}
๐ ูุฐุง ุงููุดุฑูุน ูุงุจู ููุชุทููุฑ ุจุฅุถุงูุฉ ูููุงุช PDFุ ููุงุนุฏ ุจูุงูุงุช ุฃูุจุฑุ ุฃู ุญุชู ุฑุจุทู ุจู Google Sheets.

""",

bash
Toujours afficher les dรฉtails

Copier
"embedding.py": """from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import OllamaEmbeddings

ุชุญููู ุงูุจูุงูุงุช
loader = TextLoader("data/my_knowledge.txt")
documents = loader.load()

ุชูุณูู ุงููุตูุต
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(documents)

ุฅูุดุงุก ูุงุนุฏุฉ Embeddings
embedding = OllamaEmbeddings(model="llama2")
vectorstore = Chroma.from_documents(chunks, embedding, persist_directory="db")
vectorstore.persist()
print("โ ุชู ุฅูุดุงุก ุงููุงุนุฏุฉ ุงููุนุฑููุฉ.")
""",

bash
Toujours afficher les dรฉtails

Copier
"query_context.py": """import sys
from langchain.vectorstores import Chroma
from langchain.embeddings import OllamaEmbeddings

ุฃุฎุฐ ุงูุณุคุงู ูู ุงููุณุชุฎุฏู
user_query = sys.argv[1]

ุชุญููู ูุงุนุฏุฉ ุงูุจูุงูุงุช
db = Chroma(persist_directory="db", embedding_function=OllamaEmbeddings(model="llama2"))

ุงูุจุญุซ ุนู ุงูุณูุงู ุงูุฃูุฑุจ
results = db.similarity_search(user_query, k=2)

ุทุจุงุนุฉ ุงูุณูุงู ูููููุฐุฌ
for r in results:
print(r.page_content)
""",

bash
Toujours afficher les dรฉtails

Copier
"data/my_knowledge.txt": """ุงูููุงุกุฉ ุงูููููุฉ ูู ูุฌููุน ุงูููุงุฑุงุช ูุงููุฏุฑุงุช ุงูุชู ูุญุชุงุฌูุง ุงููุฏุฑุณ ูุฅุฏุงุฑุฉ ุงููุณู.
ุงูุฏูุฏุงูุชูู ูุฑูุฒ ุนูู ุทุฑู ุงูุชุฏุฑูุณ ุงููุนุงูุฉุ ูุซู ุงูุชุนููู ุจุงูุฃูุซูุฉ ูุงูุชุนูู ุงููุดุท.
ุงููุชุงุจ ุงูุฃุจูุถ ูู ูุซููุฉ ูุฑุฌุนูุฉ ูุฅุตูุงุญ ููุธููุฉ ุงูุชุนููู ูู ุงููุบุฑุจ.
"""
}

ุฅูุดุงุก ุงููุฌูุฏุงุช
for folder in folders:
(base_path / folder).mkdir(parents=True, exist_ok=True)

ุฅูุดุงุก ุงููููุงุช
for file_name, content in files.items():
file_path = base_path / file_name
file_path.parent.mkdir(parents=True, exist_ok=True)
file_path.write_text(content, encoding="utf-8")

ุชุฌููุฒ ุงูููู ูุฃุฑุดูู ููุชุญููู
output_zip = f"/mnt/data/{project_name}.zip"
base_path.mkdir(parents=True, exist_ok=True)
import shutil
shutil.make_archive(str(base_path), 'zip', str(base_path))

output_zip

Toujours afficher les dรฉtails

Copier
Rรฉsultat
'/mnt/data/n8n-llama-custom-rag.zip'
๐ฆ ุชู ุชุฌููุฒ ูุดุฑูุน GitHub ุจูุฌุงุญ! ููููู ุชุญูููู ูู ุงูุฑุงุจุท ุงูุชุงูู:

ุชุญููู ุงููุดุฑูุน ุจุตูุบุฉ ZIP

ูุญุชูู ุนูู:

ูููุงุช ุงูุจูุงูุงุช (data/my_knowledge.txt)

ุณูุฑุจุชุงุช Python (embedding.py, query_context.py)

ููู ุชูุซููู ุดุงูู README.md ูุดุฑุญ ุทุฑููุฉ ุงูุงุณุชุฎุฏุงู ุฎุทูุฉ ุจุฎุทูุฉ.

ูู ุชุฑุบุจ ุฃู ุฃุณุงุนุฏู ุฃูุถูุง ูู ุฑูุนู ุฅูู GitHub ุฃู ุชููุฆุฉ ููู requirements.txtุ 







